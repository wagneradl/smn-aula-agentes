# ====================================================================
# AGENTE DE ATENDIMENTO A D√öVIDAS FREQUENTES
# ====================================================================
# Este agente responde a perguntas comuns usando uma base de conhecimento simples.
# √â √∫til para fornecer respostas r√°pidas sobre pol√≠ticas, processos ou informa√ß√µes
# da empresa sem precisar consultar um humano.
# ====================================================================

# Importamos as bibliotecas necess√°rias
# (estas precisam ser instaladas usando pip, conforme instru√ß√µes em configuracao/README.md)
import os
from dotenv import load_dotenv  # Para carregar as vari√°veis de ambiente
from langchain_openai import ChatOpenAI  # Modelo de linguagem para conversa
from langchain.prompts import ChatPromptTemplate  # Para criar prompts estruturados
from langchain_community.vectorstores import FAISS  # Para armazenar e buscar informa√ß√µes
from langchain_openai import OpenAIEmbeddings  # Para converter texto em n√∫meros que o computador entende
from langchain.text_splitter import RecursiveCharacterTextSplitter  # Para dividir documentos grandes
from langchain_community.document_loaders import TextLoader  # Para carregar documentos de texto

# Carregar configura√ß√µes do arquivo .env
load_dotenv()

# Chaves de API (nunca compartilhe estas chaves!)
# Voc√™ precisa obter sua pr√≥pria chave em https://platform.openai.com/api-keys
# e coloc√°-la no arquivo .env conforme explicado em configuracao/.env.exemplo
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# ====================================================================
# PARTE 1: BASE DE CONHECIMENTO
# ====================================================================
# Esta √© a base de conhecimento do seu agente. Em um sistema real, 
# isso poderia vir de documentos da empresa, mas para este exemplo
# usaremos algumas informa√ß√µes diretamente no c√≥digo.
# ====================================================================

# Informa√ß√µes de exemplo da SMN (substitua por informa√ß√µes reais da sua organiza√ß√£o)
conhecimento = """
# Pol√≠ticas de F√©rias da SMN

- Os funcion√°rios t√™m direito a 30 dias de f√©rias por ano ap√≥s 12 meses de trabalho.
- As f√©rias devem ser solicitadas com pelo menos 30 dias de anteced√™ncia.
- O sistema para solicitar f√©rias √© o Portal RH, acess√≠vel em https://rh.smn.com.br
- √â poss√≠vel vender at√© 10 dias de f√©rias.
- D√∫vidas sobre f√©rias devem ser enviadas para o e-mail ferias@smn.com.br

# Pol√≠tica de Home Office

- Os funcion√°rios podem trabalhar remotamente at√© 3 dias por semana.
- Os dias de trabalho remoto devem ser acordados com o gestor direto.
- Reuni√µes importantes sempre ocorrem √†s ter√ßas-feiras, quando todos devem estar presencialmente.
- Para trabalhar remotamente, √© necess√°rio ter uma conex√£o est√°vel e equipamentos adequados.

# Reembolso de Despesas

- Despesas de viagem a trabalho s√£o reembols√°veis mediante apresenta√ß√£o de notas fiscais.
- O prazo para solicitar reembolso √© de at√© 7 dias ap√≥s o retorno da viagem.
- O reembolso √© processado em at√© 10 dias √∫teis.
- O formul√°rio de reembolso est√° dispon√≠vel no Portal RH.
"""

# Salvamos a base de conhecimento em um arquivo tempor√°rio
with open("conhecimento_temp.txt", "w", encoding="utf-8") as f:
    f.write(conhecimento)

# ====================================================================
# PARTE 2: PREPARA√á√ÉO DA BASE DE CONHECIMENTO
# ====================================================================
# Aqui, transformamos o texto em um formato que o agente pode usar
# para encontrar rapidamente as informa√ß√µes relevantes.
# ====================================================================

# Carregar o documento
loader = TextLoader("conhecimento_temp.txt", encoding="utf-8")
documentos = loader.load()

# Dividir o documento em peda√ßos menores para facilitar a busca
divisor_texto = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
textos = divisor_texto.split_documents(documentos)

# Criar embeddings (representa√ß√µes num√©ricas do texto)
embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)

# Criar a base de conhecimento vetorial
base_conhecimento = FAISS.from_documents(textos, embeddings)

# ====================================================================
# PARTE 3: CONFIGURA√á√ÉO DO AGENTE
# ====================================================================
# Configuramos o modelo de linguagem e definimos como ele deve 
# formatar as respostas.
# ====================================================================

# Inicializar o modelo de linguagem
modelo = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model_name="gpt-3.5-turbo")

# Template para o prompt (instru√ß√£o) que ser√° enviado ao modelo
template_prompt = """
Voc√™ √© um assistente de atendimento da SMN, especializado em responder perguntas 
sobre as pol√≠ticas e procedimentos da empresa. Seja educado, conciso e direto.

Informa√ß√µes relevantes da base de conhecimento:
{contexto}

Pergunta do funcion√°rio: {pergunta}

Sua resposta (use apenas as informa√ß√µes fornecidas acima, seja breve e direto):
"""

prompt = ChatPromptTemplate.from_template(template_prompt)

# ====================================================================
# PARTE 4: FUN√á√ÉO PRINCIPAL DO AGENTE
# ====================================================================
# Esta fun√ß√£o √© o cora√ß√£o do agente - ela recebe uma pergunta, busca 
# informa√ß√µes relevantes, e gera uma resposta.
# ====================================================================

def responder_pergunta(pergunta):
    """
    Fun√ß√£o principal do agente que responde a perguntas com base na base de conhecimento.
    
    Args:
        pergunta (str): A pergunta do usu√°rio
        
    Returns:
        str: A resposta gerada pelo agente
    """
    # Passo 1: Buscar documentos relevantes para a pergunta
    documentos_relevantes = base_conhecimento.similarity_search(pergunta, k=3)
    
    # Passo 2: Extrair o conte√∫do dos documentos
    contexto = "\n\n".join([doc.page_content for doc in documentos_relevantes])
    
    # Passo 3: Criar o prompt com o contexto e a pergunta
    mensagens = prompt.format_messages(contexto=contexto, pergunta=pergunta)
    
    # Passo 4: Gerar a resposta usando o modelo de linguagem
    resposta = modelo.invoke(mensagens)
    
    return resposta.content

# ====================================================================
# PARTE 5: INTERFACE SIMPLES PARA TESTAR O AGENTE
# ====================================================================
# Uma interface de linha de comando para interagir com o agente.
# ====================================================================

def interface_simples():
    """Interface de linha de comando para interagir com o agente."""
    print("="*70)
    print("ü§ñ AGENTE DE ATENDIMENTO A D√öVIDAS FREQUENTES DA SMN")
    print("="*70)
    print("Fa√ßa perguntas sobre pol√≠ticas da empresa, como f√©rias, home office, etc.")
    print("Digite 'sair' para encerrar.")
    print("="*70)
    
    while True:
        pergunta = input("\nüí¨ Sua pergunta: ")
        
        if pergunta.lower() == "sair":
            print("\nüëã At√© a pr√≥xima!")
            break
        
        print("\nü§ñ Buscando resposta...\n")
        try:
            resposta = responder_pergunta(pergunta)
            print(f"üîπ {resposta}\n")
        except Exception as e:
            print(f"‚ùå Ocorreu um erro: {str(e)}\n")
            print("Por favor, verifique sua conex√£o com a internet e a configura√ß√£o da API.")

# ====================================================================
# PARTE 6: EXECUTAR O AGENTE
# ====================================================================
# Executamos a interface se este arquivo for executado diretamente.
# ====================================================================

if __name__ == "__main__":
    interface_simples()
    
    # Limpeza do arquivo tempor√°rio
    if os.path.exists("conhecimento_temp.txt"):
        os.remove("conhecimento_temp.txt")